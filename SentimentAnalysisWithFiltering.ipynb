{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: contractions in ./opt/anaconda3/lib/python3.7/site-packages (0.0.45)\n",
      "Requirement already satisfied: textsearch in ./opt/anaconda3/lib/python3.7/site-packages (from contractions) (0.0.17)\n",
      "Requirement already satisfied: pyahocorasick in ./opt/anaconda3/lib/python3.7/site-packages (from textsearch->contractions) (1.4.0)\n",
      "Requirement already satisfied: Unidecode in ./opt/anaconda3/lib/python3.7/site-packages (from textsearch->contractions) (1.1.2)\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/Users/victornathanael/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: afinn in ./opt/anaconda3/lib/python3.7/site-packages (0.1)\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/Users/victornathanael/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Installing Afinn Lexicon\n",
    "!pip install contractions\n",
    "!pip install afinn\n",
    "from afinn import Afinn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries for Processing the Data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re,string,unicodedata\n",
    "%matplotlib inline\n",
    "import contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries For Text Preprocessing\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/victornathanael/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/victornathanael/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/victornathanael/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Preparing the Dict\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding Labels\n",
    "import csv\n",
    "\n",
    "with open('data.csv',newline='',encoding = 'unicode_escape') as f:\n",
    "    r = csv.reader(f)\n",
    "    data = [line for line in r]\n",
    "with open('data.csv','w',newline='', encoding= 'unicode_escape') as f:\n",
    "    w = csv.writer(f)\n",
    "    w.writerow(['sentiment_from_dataset','news'])\n",
    "    w.writerows(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  sentiment_from_dataset                                               news\n",
      "0                neutral  According to Gran , the company has no plans t...\n",
      "1                neutral  Technopolis plans to develop in stages an area...\n",
      "2               negative  The international electronic industry company ...\n",
      "3               positive  With the new production plant the company woul...\n",
      "4               positive  According to the company 's updated strategy f...\n"
     ]
    }
   ],
   "source": [
    "#Import the dataset\n",
    "\n",
    "data = pd.read_csv(\"data.csv\", encoding= 'unicode_escape')\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  sentiment_from_dataset                                               news\n",
      "0                neutral  According to Gran , the company has no plans t...\n",
      "1                neutral  Technopolis plans to develop in stages an area...\n",
      "2               negative  The international electronic industry company ...\n",
      "3               positive  With the new production plant the company woul...\n",
      "4               positive  According to the company 's updated strategy f...\n"
     ]
    }
   ],
   "source": [
    "#Remove unused column (Name and Date) and missing values\n",
    "data = data.dropna()\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  sentiment_from_dataset                                               news\n",
      "0                neutral  according gran company plans move production r...\n",
      "1                neutral  technopolis plans develop stages area less 100...\n",
      "2               negative  international electronic industry company elco...\n",
      "3               positive  new production plant company would increase ca...\n",
      "4               positive  according company updated strategy years 20092...\n"
     ]
    }
   ],
   "source": [
    "#Preprocessing\n",
    "\n",
    "#Case Folding\n",
    "data['news'] = data['news'].str.lower() #Lowercase the sentence\n",
    "\n",
    "#Tokenizing \n",
    "data['news'] = data['news'].str.strip() #Remove Leading Space and Trailing Space\n",
    "\n",
    "from string import punctuation\n",
    "\n",
    "def remove_punct(text):\n",
    "  for punctuations in punctuation:\n",
    "    text = text.replace(punctuations, '')\n",
    "  return text\n",
    "\n",
    "data['news'] = data['news'].apply(remove_punct) #Remove Punctuation\n",
    "\n",
    "def remove_special_char(text, remove_digits=True):\n",
    "  pattern = r'[^a-zA-z0-9\\s]'\n",
    "  text = re.sub(pattern, '', text)\n",
    "  return text\n",
    "\n",
    "data['news'] = data['news'].apply(remove_special_char) #Remove Symbols or other special characters\n",
    "\n",
    "def expand_contractions(con_text):\n",
    "  con_text = contractions.fix(con_text)\n",
    "  return con_text\n",
    "  \n",
    "data['news'] = data['news'].apply(expand_contractions) #Expand English Contractions (Ex : I've -> I have)\n",
    "\n",
    "def remove_accented_chars(text):\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    return text\n",
    "\n",
    "\n",
    "data['news'] = data['news'].apply(remove_accented_chars) #Remove macrons & accented characters\n",
    "\n",
    "#Filtering\n",
    "tokenizer = ToktokTokenizer()\n",
    "stopword_list = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(text, is_lower_case=False):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    if is_lower_case:\n",
    "        filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
    "    else:\n",
    "        filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n",
    "    filtered_text = ' '.join(filtered_tokens)    \n",
    "    return filtered_text\n",
    "\n",
    "data['news'] = data['news'].apply(remove_stopwords) \n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sentiment_from_dataset  \\\n",
      "0                   neutral   \n",
      "1                   neutral   \n",
      "2                  negative   \n",
      "3                  positive   \n",
      "4                  positive   \n",
      "...                     ...   \n",
      "4841               negative   \n",
      "4842                neutral   \n",
      "4843               negative   \n",
      "4844               negative   \n",
      "4845               negative   \n",
      "\n",
      "                                                   news  afinn_score  \\\n",
      "0     according gran company plans move production r...          1.0   \n",
      "1     technopolis plans develop stages area less 100...          0.0   \n",
      "2     international electronic industry company elco...          0.0   \n",
      "3     new production plant company would increase ca...          4.0   \n",
      "4     according company updated strategy years 20092...          4.0   \n",
      "...                                                 ...          ...   \n",
      "4841  london marketwatch share prices ended lower lo...         -3.0   \n",
      "4842  rinkuskiai beer sales fell 65 per cent 416 mil...          0.0   \n",
      "4843  operating profit fell eur 354 mn eur 688 mn 20...          4.0   \n",
      "4844  net sales paper segment decreased eur 2216 mn ...          3.0   \n",
      "4845  sales finland decreased 105 january sales outs...         -1.0   \n",
      "\n",
      "     sentiment_results_afinn  \n",
      "0                   positive  \n",
      "1                    neutral  \n",
      "2                    neutral  \n",
      "3                   positive  \n",
      "4                   positive  \n",
      "...                      ...  \n",
      "4841                negative  \n",
      "4842                 neutral  \n",
      "4843                positive  \n",
      "4844                positive  \n",
      "4845                negative  \n",
      "\n",
      "[4846 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "#Using Afinn Lexicon to classify the sentence\n",
    "af = Afinn()\n",
    "\n",
    "def afinn_sent_analysis(text):\n",
    "  score = af.score(text)\n",
    "  return score\n",
    "\n",
    "#applying the function to Normalized Comments\n",
    "data['afinn_score'] = [afinn_sent_analysis(comm) for comm in data['news']]\n",
    "\n",
    "#If Afinn Score is more than 0 : The text contains Positive Sentiment\n",
    "                #  less than 0 : The text contains Negative Sentiment\n",
    "                #  equals to 0 : The text contains Neutral Sentiment\n",
    "        \n",
    "def afinn_sent_category(score):\n",
    "  categories = ['positive','negative','neutral']\n",
    "  if score > 0:\n",
    "    return categories[0]\n",
    "  elif score < 0:\n",
    "    return categories[1]\n",
    "  else:\n",
    "    return categories[2]  \n",
    "\n",
    "data['sentiment_results_afinn'] = [afinn_sent_category(scr) for scr in data['afinn_score']]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sentiment_from_dataset  \\\n",
      "0                   neutral   \n",
      "1                   neutral   \n",
      "2                  negative   \n",
      "3                  positive   \n",
      "4                  positive   \n",
      "...                     ...   \n",
      "4841               negative   \n",
      "4842                neutral   \n",
      "4843               negative   \n",
      "4844               negative   \n",
      "4845               negative   \n",
      "\n",
      "                                                   news  afinn_score  \\\n",
      "0     according gran company plans move production r...          1.0   \n",
      "1     technopolis plans develop stages area less 100...          0.0   \n",
      "2     international electronic industry company elco...          0.0   \n",
      "3     new production plant company would increase ca...          4.0   \n",
      "4     according company updated strategy years 20092...          4.0   \n",
      "...                                                 ...          ...   \n",
      "4841  london marketwatch share prices ended lower lo...         -3.0   \n",
      "4842  rinkuskiai beer sales fell 65 per cent 416 mil...          0.0   \n",
      "4843  operating profit fell eur 354 mn eur 688 mn 20...          4.0   \n",
      "4844  net sales paper segment decreased eur 2216 mn ...          3.0   \n",
      "4845  sales finland decreased 105 january sales outs...         -1.0   \n",
      "\n",
      "     sentiment_results_afinn  comparison  \n",
      "0                   positive       False  \n",
      "1                    neutral        True  \n",
      "2                    neutral       False  \n",
      "3                   positive        True  \n",
      "4                   positive        True  \n",
      "...                      ...         ...  \n",
      "4841                negative        True  \n",
      "4842                 neutral        True  \n",
      "4843                positive       False  \n",
      "4844                positive       False  \n",
      "4845                negative        True  \n",
      "\n",
      "[4846 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "data['comparison'] = (data['sentiment_from_dataset'] == data['sentiment_results_afinn'])\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     2885\n",
       "False    1961\n",
       "Name: comparison, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"comparison\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.5954592363261094\n"
     ]
    }
   ],
   "source": [
    "accuracy = 2885/4845\n",
    "print(\"Accuracy = \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
